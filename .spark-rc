#!/usr/bin/env bash

if [ -z "$sparks" ]; then
  export sparks="$HOME/sparks"
elif [ ! -d "$sparks" ]; then
  echo "\$sparks directory $sparks not actually a directory!" 1>&2
fi
mkdir -p "$sparks"

function contains() {
    local n=$#
    local value=${!n}
    for ((i=1;i < $#;i++)) {
        if [ "${!i}" == "${value}" ]; then
            return 0
        fi
    }
    return 1
}

parse_spark_helper_args() {

  # This function parses command-line arguments and sets the following variables:
  #
  #   - sh_clean_arg: whether to pass "clean" to `mvn package`, if a Spark version is built.
  #   - sh_sha: the git SHA to build Spark at
  #   - sh_version: a Spark version to download a pre-built release of; identical to $sh_sha, only
  #     populated if the SHA is actually a valid Spark version number.
  #   - sh_hadoop_version: Hadoop profile / version number.
  #   - sh_hadoop_args: Hadoop profile and version information to be passed to `mvn package`.
  #   - sh_spark_dir: local directory that the selected Spark version will be found/built in.

  sh_clean_arg=
  if [ "$1" == "--clean" ]; then
    sh_clean_arg="clean"
    shift
  fi

  if [ $# -gt 0 ]; then
    sh_sha="$1"
    shift
  fi

  if [ -z "$sh_sha" ]; then
    sh_sha="$(git --no-pager log --no-walk --format="%H")"
  fi

  local spark_versions=("1.1.1" "1.2.1" "1.2.2" "1.3.0" "1.3.1" "1.4.0" "1.4.1")
  if contains "${spark_versions[@]}" "$sh_sha"; then
    echo "version! $sh_sha"
    sh_version="$sh_sha"
  fi

  if [ $# -gt 0 ]; then
    sh_hadoop_version="$1"
    shift
  else
    sh_hadoop_version="${SPARK_HADOOP_VERSION:-2.4}"
  fi

  local hadoop_profiles=("2.2" "2.3" "2.4" "2.6")
  if ! contains "${hadoop_profiles[@]}" "$sh_hadoop_version"; then
    echo "Invalid hadoop version: $sh_hadoop_version; choose from ${hadoop_profiles[@]}" 1>&2
    return 1
  fi

  sh_hadoop_args="-Phadoop-${sh_hadoop_version} -Dhadoop.version=${sh_hadoop_version}.0"

  sh_spark_dir="spark-${sh_sha}-bin-hadoop${sh_hadoop_version}"
  if [ -n "$sparks" ]; then
    sh_spark_dir="$sparks/$sh_spark_dir"
  fi

}

alias spark-select=". spark-select-impl"
alias spark-history-opts=". spark-history-opts-impl"
