#!/usr/bin/env bash

if [ -z "$sparks" ]; then
  export sparks="$HOME/sparks"
elif [ ! -d "$sparks" ]; then
  echo "\$sparks directory $sparks not actually a directory!" 1>&2
fi
mkdir -p "$sparks"

function contains() {
    local n=$#
    local value=${!n}
    for ((i=1;i < $#;i++)) {
        if [ "${!i}" == "${value}" ]; then
            return 0
        fi
    }
    return 1
}

parse_spark_helper_args() {

  # This function parses command-line arguments and sets the following variables:
  #
  #   - sh_clean_arg: whether to pass "clean" to `mvn package`, if a Spark version is built.
  #   - sh_sha: the git SHA to build Spark at
  #   - sh_version: a Spark version to download a pre-built release of; identical to $sh_sha, only
  #     populated if the SHA is actually a valid Spark version number.
  #   - sh_hadoop_version: Hadoop profile / version number.
  #   - sh_hadoop_args: Hadoop profile and version information to be passed to `mvn package`.
  #   - sh_spark_dir: local directory that the selected Spark version will be found/built in.

  while getopts ":cf" opt; do
    case $opt in
      c)
        sh_clean_arg="clean"
        ;;
      f)
        sh_force_build=1
        ;;
      \?)
        break
        ;;
    esac
  done
  shift $((OPTIND-1))

  export sh_clean_arg
  export sh_force_build

  if [ $# -gt 0 ]; then
    sh_sha="$1"
    shift
  fi

  if [ -z "$sh_sha" ]; then
    sh_sha="$(git --no-pager log --no-walk --format="%H")"
  fi

  export sh_sha

  local spark_versions=("1.1.1" "1.2.1" "1.2.2" "1.3.0" "1.3.1" "1.4.0" "1.4.1" "1.5.0" "1.5.1" "1.5.2" "1.6.0" "1.6.1" "1.6.2" "2.0.0" "2.0.1", "2.0.2" "2.1.0" "2.1.1" "2.1.2" "2.2.0")
  if contains "${spark_versions[@]}" "$sh_sha"; then
    echo "found version: $sh_sha"
    export sh_version="$sh_sha"
  fi

  if [ $# -gt 0 ]; then
    sh_hadoop_version="$1"
    shift
  else
    sh_hadoop_version="${SPARK_HELPERS_HADOOP_VERSION:-2.6}"
  fi
  export sh_hadoop_version

  local hadoop_profiles=("2.3" "2.4" "2.6")
  if ! contains "${hadoop_profiles[@]}" "$sh_hadoop_version"; then
    echo "Invalid hadoop version: $sh_hadoop_version; choose from ${hadoop_profiles[@]}" 1>&2
    return 1
  fi

  export sh_hadoop_args="-Phadoop-${sh_hadoop_version} -Dhadoop.version=${sh_hadoop_version}.0"

  sh_spark_dir="spark-${sh_sha}-bin-hadoop${sh_hadoop_version}"
  if [ -n "$sparks" ]; then
    export sh_spark_dir="$sparks/$sh_spark_dir"
  fi

}

alias spark-select=". spark-select-impl"
alias spark-history-opts=". spark-history-opts-impl"

wel() {
  wrap-event-log "$@"
}
