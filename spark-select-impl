#!/usr/bin/env bash

dir="$(dirname "${BASH_SOURCE[0]}")"
source "$dir"/.spark-rc

parse_spark_helper_args "$@"

if [ ! -d "$sh_spark_dir" ]; then
  if [ -n "$sh_version" ]; then
    echo "Fetching released version: $sh_version"
    tgz="$(basename "$sh_spark_dir").tgz"
    local_tgz="$sparks/$tgz"
    url="${SPARK_MIRROR:-http://mirrors.advancedhosters.com/apache}/spark/spark-${sh_version}/${tgz}"
    echo "$sh_spark_dir not found; fetching $url"
    wget "$url" -O "$local_tgz"
    tar xvzf "$local_tgz" -C "$sparks"
  else
    echo "$sh_spark_dir not found; cloning and building..."
    spark-build
  fi
fi
export SPARK_HOME="$sh_spark_dir"

sh_sha=
sh_hadoop_version=
sh_clean_arg=
sh_hadoop_args=
sh_version=
sh_spark_dir=
