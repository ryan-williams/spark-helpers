#!/usr/bin/env bash

# Given a SHA and a Hadoop version, clone Spark into a folder namespaced
# according to those arguments, check out the SHA, and build/package Spark.

set -e
if [ -z "$sh_sha" ]; then
  dir="$(dirname "${BASH_SOURCE[0]}")"
  source "$dir"/.spark-rc

  echo "build parsing"
  parse_spark_helper_args "$@"
fi

. spark-clone

assembly_jar_dir="$sh_spark_dir/assembly/target/scala-${SPARK_SCALA_VERSION:-2.10}"
if [ -d "$assembly_jar_dir" ]; then
  assembly_jar="$(ls -A "$assembly_jar_dir"/*.jar)"
  if [ "$assembly_jar" ]; then
    echo "Found assembly JAR: $assembly_jar"
    if [ "$sh_force_build" ]; then
      echo "Building anyway"
    else
      exit 0
    fi
  fi
fi

if [ -z "$ZINC_PORT" ]; then
  attempts=0
  ZINC_PORT=3030
  echo "Attempting to find free \$ZINC_PORT starting from $port"
  while [ 1 ]; do
    if ! lsof -i :$ZINC_PORT; then
      break
    fi
    let ZINC_PORT=$ZINC_PORT+1
    let attempts=$attempts+1
    if [ $attempts -ge 100 ]; then
      echo "Quitting after $attempts attempts to find a free port for zinc" 1>&2
      exit 1
    fi
  done
fi
echo "zinc port: $ZINC_PORT"
export ZINC_PORT

cmd="build/mvn --force $SPARK_BUILD_ARGS $sh_hadoop_args -DskipTests -DzincPort="${ZINC_PORT:-3030}" $sh_clean_arg package"
echo "Running mvn cmd: $cmd"
$cmd
